(base) jupyter-st125462@puffer:~/ExtendedUrbansound$ python train_kfold.py --model_name alexnet --pretrained --freeze_features --batch_size 64 --epochs 5

================================================================================
Training on Fold 1
Train Folds: [2, 3, 4, 5, 6, 7, 8, 9]
Val Fold: [10]
Test Fold: [1]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [01:29<00:00,  8.07it/s, loss=0.552, acc=81.6]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:12<00:00,  7.20it/s]
Epoch 1/5 - Train Loss: 0.5516, Train Acc: 81.57%, Val Loss: 0.9837, Val Acc: 70.48%, Best Val Acc: 70.48% (Epoch 1)
Epoch 2:  28%|████████████████████████████▉                                                                         | Epoch 2:  29%|█████████████████████████████▎                                                                        | Epoch 2:  29%|█████████████████████████████▎                                                                        | Epoch 2:  29%|█████████████████████████████▎                                                                        | Epoch 2:  29%|█████████████████████████████▎                                                                        | Epoch 2:  29%|█████████████████████████████▎                                                                        | Epoch 2:  29%|█████████████████████████████▉                                                                        | Epoch 2:  29%|█████████████████████████████▉                                                                        | Epoch 2:  29%|█████████████████████████████▉                                                                        | Epoch 2:  29%|██████████████████████████████▌                                                                         Epoch 2:  29%|██████████████████████████████▌                                                                         Epoch 2:  30%|███████████████████████████████                                                                         Epoch 2:  30%|██████████████████████████████▍                                                                       | Epoch 2:  30%|██████████████████████████████▍                                                                       | Epoch 2:  30%|███████████████████████████████                                                                         Epoch 2:  30%|███████████████████████████████                                                                         Epoch 2:  30%|███████████████████████████████                                                                         Epoch 2:  31%|███████████████████████████████▊                                                                        Epoch 2:  31%|███████████████████████████████▊                                                                        Epoch 2:  31%|███████████████████████████████▊                                                                        Epoch 2:  31%|███████████████████████████████▊                                                                        Epoch 2:  31%|████████████████████████████████▏                                                                       Epoch 2:  31%|████████████████████████████████▏                                                                       Epoch 2:  31%|████████████████████████████████▏                                                                       Epoch 2:  31%|████████████████████████████████▏                                                                       Epoch 2:  31%|████████████████████████████████▏                                                                       Epoch 2:  32%|████████████████████████████████▊                                                                       Epoch 2:  32%|████████████████████████████████▊                                                                       Epoch 2:  32%|████████████████████████████████▊                                                                       Epoch 2:  32%|████████████████████████████████▊                                                                       Epoch 2:  32%|████████████████████████████████▊                                                                       Epoch 2:  32%|█████████████████████████████████▍                                                                      Epoch 2:  32%|█████████████████████████████████▍                                                                      Epoch 2:  32%|█████████████████████████████████▍                                                                      Epoch 2:  32%|█████████████████████████████████▍                                                                      Epoch 2:  32%|████████████████████████████████▋                                                                     | Epoch 2:  32%|████████████████████████████████▋                                                                     | Epoch 2:  33%|█████████████████████████████████▍                                                                    | Epoch 2:  33%|█████████████████████████████████▍                                                                    | Epoch 2:  33%|█████████████████████████████████▍                                                                    | Epoch 2:  33%|██████████████████████████████████                                                                      Epoch 2:  33%|██████████████████████████████████▌                                                                     Epoch 2:  33%|█████████████████████████████████▊                                                                    | Epoch 2:  33%|█████████████████████████████████▊                                                                    | Epoch 2:  33%|██████████████████████████████████▌                                                                     Epoch 2:  33%|██████████████████████████████████▌                                                                     Epoch 2:  33%|██████████████████████████████████▌                                                                     Epoch 2:  34%|███████████████████████████████████▏                                                                    Epoch 2:  34%|███████████████████████████████████▏                                                                    Epoch 2:  34%|███████████████████████████████████▏                                                                    Epoch 2:  34%|██████████████████████████████████▌                                                                   | Epoch 2:  34%|██████████████████████████████████▉                                                                   | Epoch 2:  34%|██████████████████████████████████▉                                                                   | Epoch 2:  34%|███████████████████████████████████▎                                                                   |Epoch 2:  34%|██████████████████████████████████▉                                                                   | Epoch 2:  34%|███████████████████████████████████▎                                                                   |Epoch 2:  34%|██████████████████████████████████▉                                                                   | Epoch 2:  35%|███████████████████████████████████▋                                                                  | Epoch 2:  35%|███████████████████████████████████▋                                                                  | Epoch 2:  35%|███████████████████████████████████▋                                                                  | Epoch 2:  35%|███████████████████████████████████▋                                                                  | Epoch 2:  35%|████████████████████████████████████                                                                  | Epoch 2:  35%|████████████████████████████████████                                                                  | Epoch 2:  35%|████████████████████████████████████                                                                  | Epoch 2:  35%|████████████████████████████████████                                                                  | Epoch 2:  35%|████████████████████████████████████                                                                  | Epoch 2:  36%|████████████████████████████████████▋                                                                 | Epoch 2:  36%|████████████████████████████████████▋                                                                 | Epoch 2:  36%|████████████████████████████████████▋                                                                 | Epoch 2:  36%|████████████████████████████████████▋                                                                 | Epoch 2:  36%|████████████████████████████████████▋                                                                 | Epoch 2:  37%|█████████████████████████████████████▏                                                                | Epoch 2:  37%|█████████████████████████████████████▏                                                                | Epoch 2:  37%|█████████████████████████████████████▏                                                                | Epoch 2:  37%|█████████████████████████████████████▏                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  37%|█████████████████████████████████████▋                                                                | Epoch 2:  38%|██████████████████████████████████████▎                                                               | Epoch 2:  38%|██████████████████████████████████████▎                                                               | Epoch 2:  38%|██████████████████████████████████████▎                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  38%|██████████████████████████████████████▋                                                               | Epoch 2:  39%|███████████████████████████████████████▎                                                              | Epoch 2:  39%|███████████████████████████████████████▎                                                              | Epoch 2:  39%|███████████████████████████████████████▎                                                              | Epoch 2:  39%|███████████████████████████████████████▎                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  39%|███████████████████████████████████████▊                                                              | Epoch 2:  40%|████████████████████████████████████████▍                                                             | Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [01:29<00:00,  8.07it/s, loss=0.322, acc=89.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:11<00:00,  7.64it/s]
Epoch 2/5 - Train Loss: 0.3223, Train Acc: 89.67%, Val Loss: 0.8886, Val Acc: 75.35%, Best Val Acc: 75.35% (Epoch 2)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [01:29<00:00,  8.11it/s, loss=0.286, acc=90.9]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:11<00:00,  7.69it/s]
Epoch 3/5 - Train Loss: 0.2861, Train Acc: 90.90%, Val Loss: 0.8699, Val Acc: 76.90%, Best Val Acc: 76.90% (Epoch 3)
Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [01:29<00:00,  8.11it/s, loss=0.258, acc=92.1]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:11<00:00,  7.69it/s]
Epoch 4/5 - Train Loss: 0.2581, Train Acc: 92.09%, Val Loss: 1.1538, Val Acc: 77.30%, Best Val Acc: 77.30% (Epoch 4)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [01:30<00:00,  8.06it/s, loss=0.234, acc=92.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:11<00:00,  7.61it/s]
Epoch 5/5 - Train Loss: 0.2340, Train Acc: 92.76%, Val Loss: 1.3209, Val Acc: 75.33%, Best Val Acc: 77.30% (Epoch 4)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.43it/s]
Skipping GradCAM visualization for frozen models

Fold 1 Evaluation:
Test Loss: 1.5848, Test Accuracy: 72.70%

================================================================================
Training on Fold 2
Train Folds: [3, 4, 5, 6, 7, 8, 9, 10]
Val Fold: [1]
Test Fold: [2]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:31<00:00,  7.89it/s, loss=0.553, acc=81.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.27it/s]
Epoch 1/5 - Train Loss: 0.5531, Train Acc: 81.43%, Val Loss: 0.9037, Val Acc: 75.60%, Best Val Acc: 75.60% (Epoch 1)
Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:32<00:00,  7.86it/s, loss=0.336, acc=89]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.51it/s]
Epoch 2/5 - Train Loss: 0.3359, Train Acc: 89.04%, Val Loss: 1.1720, Val Acc: 73.84%, Best Val Acc: 75.60% (Epoch 1)
Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:29<00:00,  8.11it/s, loss=0.285, acc=91]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.45it/s]
Epoch 3/5 - Train Loss: 0.2853, Train Acc: 90.99%, Val Loss: 1.0130, Val Acc: 76.93%, Best Val Acc: 76.93% (Epoch 3)
Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:30<00:00,  8.02it/s, loss=0.259, acc=92]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.51it/s]
Epoch 4/5 - Train Loss: 0.2593, Train Acc: 92.03%, Val Loss: 0.9032, Val Acc: 78.73%, Best Val Acc: 78.73% (Epoch 4)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:29<00:00,  8.06it/s, loss=0.247, acc=92.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.73it/s]
Epoch 5/5 - Train Loss: 0.2475, Train Acc: 92.44%, Val Loss: 0.9546, Val Acc: 76.76%, Best Val Acc: 78.73% (Epoch 4)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.80it/s]
Skipping GradCAM visualization for frozen models

Fold 2 Evaluation:
Test Loss: 0.8968, Test Accuracy: 74.23%

================================================================================
Training on Fold 3
Train Folds: [1, 4, 5, 6, 7, 8, 9, 10]
Val Fold: [2]
Test Fold: [3]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:32<00:00,  7.87it/s, loss=0.55, acc=81.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.28it/s]
Epoch 1/5 - Train Loss: 0.5498, Train Acc: 81.65%, Val Loss: 1.0214, Val Acc: 70.52%, Best Val Acc: 70.52% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:29<00:00,  8.12it/s, loss=0.326, acc=89.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.66it/s]
Epoch 2/5 - Train Loss: 0.3263, Train Acc: 89.43%, Val Loss: 0.9080, Val Acc: 73.33%, Best Val Acc: 73.33% (Epoch 2)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:29<00:00,  8.05it/s, loss=0.288, acc=90.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.39it/s]
Epoch 3/5 - Train Loss: 0.2878, Train Acc: 90.81%, Val Loss: 1.1202, Val Acc: 75.29%, Best Val Acc: 75.29% (Epoch 3)
Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:30<00:00,  8.00it/s, loss=0.262, acc=92]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.34it/s]
Epoch 4/5 - Train Loss: 0.2615, Train Acc: 91.98%, Val Loss: 1.0463, Val Acc: 74.57%, Best Val Acc: 75.29% (Epoch 3)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [01:31<00:00,  7.94it/s, loss=0.228, acc=92.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.63it/s]
Epoch 5/5 - Train Loss: 0.2285, Train Acc: 92.85%, Val Loss: 0.8972, Val Acc: 77.13%, Best Val Acc: 77.13% (Epoch 5)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:11<00:00,  7.65it/s]
Skipping GradCAM visualization for frozen models

Fold 3 Evaluation:
Test Loss: 0.9718, Test Accuracy: 74.33%

================================================================================
Training on Fold 4
Train Folds: [1, 2, 5, 6, 7, 8, 9, 10]
Val Fold: [3]
Test Fold: [4]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:29<00:00,  8.07it/s, loss=0.541, acc=82]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.56it/s]
Epoch 1/5 - Train Loss: 0.5413, Train Acc: 82.05%, Val Loss: 0.9172, Val Acc: 72.13%, Best Val Acc: 72.13% (Epoch 1)
Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:30<00:00,  8.01it/s, loss=0.344, acc=89]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.41it/s]
Epoch 2/5 - Train Loss: 0.3440, Train Acc: 89.05%, Val Loss: 1.0867, Val Acc: 70.19%, Best Val Acc: 72.13% (Epoch 1)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:29<00:00,  8.07it/s, loss=0.281, acc=91.1]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.29it/s]
Epoch 3/5 - Train Loss: 0.2806, Train Acc: 91.08%, Val Loss: 1.1171, Val Acc: 71.46%, Best Val Acc: 72.13% (Epoch 1)
Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:29<00:00,  8.04it/s, loss=0.259, acc=92]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.40it/s]
Epoch 4/5 - Train Loss: 0.2587, Train Acc: 91.95%, Val Loss: 1.1613, Val Acc: 71.86%, Best Val Acc: 72.13% (Epoch 1)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:30<00:00,  8.02it/s, loss=0.235, acc=92.6]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:12<00:00,  7.33it/s]
Epoch 5/5 - Train Loss: 0.2351, Train Acc: 92.64%, Val Loss: 1.0508, Val Acc: 71.43%, Best Val Acc: 72.13% (Epoch 1)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.28it/s]
Skipping GradCAM visualization for frozen models

Fold 4 Evaluation:
Test Loss: 0.8781, Test Accuracy: 71.89%

================================================================================
Training on Fold 5
Train Folds: [1, 2, 3, 6, 7, 8, 9, 10]
Val Fold: [4]
Test Fold: [5]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:29<00:00,  8.11it/s, loss=0.539, acc=82]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.36it/s]
Epoch 1/5 - Train Loss: 0.5393, Train Acc: 81.97%, Val Loss: 0.8739, Val Acc: 74.23%, Best Val Acc: 74.23% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:28<00:00,  8.15it/s, loss=0.324, acc=89.5]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.60it/s]
Epoch 2/5 - Train Loss: 0.3244, Train Acc: 89.48%, Val Loss: 0.9168, Val Acc: 75.63%, Best Val Acc: 75.63% (Epoch 2)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:29<00:00,  8.05it/s, loss=0.289, acc=90.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.56it/s]
Epoch 3/5 - Train Loss: 0.2892, Train Acc: 90.70%, Val Loss: 0.8883, Val Acc: 76.93%, Best Val Acc: 76.93% (Epoch 3)
Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:29<00:00,  8.08it/s, loss=0.258, acc=91.9]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.56it/s]
Epoch 4/5 - Train Loss: 0.2584, Train Acc: 91.89%, Val Loss: 0.9870, Val Acc: 74.08%, Best Val Acc: 76.93% (Epoch 3)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:29<00:00,  8.10it/s, loss=0.236, acc=92.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.50it/s]
Epoch 5/5 - Train Loss: 0.2364, Train Acc: 92.77%, Val Loss: 0.9282, Val Acc: 74.90%, Best Val Acc: 76.93% (Epoch 3)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.46it/s]
Skipping GradCAM visualization for frozen models

Fold 5 Evaluation:
Test Loss: 1.6872, Test Accuracy: 71.95%

================================================================================
Training on Fold 6
Train Folds: [1, 2, 3, 4, 7, 8, 9, 10]
Val Fold: [5]
Test Fold: [6]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:31<00:00,  7.92it/s, loss=0.53, acc=82.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.43it/s]
Epoch 1/5 - Train Loss: 0.5302, Train Acc: 82.36%, Val Loss: 1.3515, Val Acc: 72.61%, Best Val Acc: 72.61% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:30<00:00,  7.97it/s, loss=0.331, acc=89.3]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.53it/s]
Epoch 2/5 - Train Loss: 0.3312, Train Acc: 89.25%, Val Loss: 1.6430, Val Acc: 72.27%, Best Val Acc: 72.61% (Epoch 1)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:29<00:00,  8.10it/s, loss=0.288, acc=91.1]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.55it/s]
Epoch 3/5 - Train Loss: 0.2880, Train Acc: 91.06%, Val Loss: 1.6659, Val Acc: 71.22%, Best Val Acc: 72.61% (Epoch 1)
Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:29<00:00,  8.10it/s, loss=0.258, acc=92]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.33it/s]
Epoch 4/5 - Train Loss: 0.2582, Train Acc: 91.96%, Val Loss: 1.5891, Val Acc: 69.99%, Best Val Acc: 72.61% (Epoch 1)
Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 723/723 [01:30<00:00,  8.01it/s, loss=0.24, acc=92.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.40it/s]
Epoch 5/5 - Train Loss: 0.2397, Train Acc: 92.69%, Val Loss: 1.5246, Val Acc: 70.64%, Best Val Acc: 72.61% (Epoch 1)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.43it/s]
Skipping GradCAM visualization for frozen models

Fold 6 Evaluation:
Test Loss: 1.0950, Test Accuracy: 68.70%

================================================================================
Training on Fold 7
Train Folds: [1, 2, 3, 4, 5, 8, 9, 10]
Val Fold: [6]
Test Fold: [7]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:28<00:00,  8.16it/s, loss=0.548, acc=81.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.37it/s]
Epoch 1/5 - Train Loss: 0.5475, Train Acc: 81.80%, Val Loss: 0.9355, Val Acc: 70.89%, Best Val Acc: 70.89% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:32<00:00,  7.84it/s, loss=0.325, acc=89.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.18it/s]
Epoch 2/5 - Train Loss: 0.3254, Train Acc: 89.43%, Val Loss: 0.8576, Val Acc: 74.29%, Best Val Acc: 74.29% (Epoch 2)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:32<00:00,  7.80it/s, loss=0.278, acc=91.2]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.39it/s]
Epoch 3/5 - Train Loss: 0.2783, Train Acc: 91.21%, Val Loss: 0.9657, Val Acc: 74.76%, Best Val Acc: 74.76% (Epoch 3)
Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:32<00:00,  7.83it/s, loss=0.25, acc=92.2]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.34it/s]
Epoch 4/5 - Train Loss: 0.2497, Train Acc: 92.18%, Val Loss: 1.4473, Val Acc: 72.20%, Best Val Acc: 74.76% (Epoch 3)
Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 722/722 [01:32<00:00,  7.81it/s, loss=0.24, acc=92.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.32it/s]
Epoch 5/5 - Train Loss: 0.2402, Train Acc: 92.71%, Val Loss: 1.2496, Val Acc: 71.94%, Best Val Acc: 74.76% (Epoch 3)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.45it/s]
Skipping GradCAM visualization for frozen models

Fold 7 Evaluation:
Test Loss: 0.8199, Test Accuracy: 74.11%

================================================================================
Training on Fold 8
Train Folds: [1, 2, 3, 4, 5, 6, 9, 10]
Val Fold: [7]
Test Fold: [8]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 725/725 [01:31<00:00,  7.88it/s, loss=0.541, acc=82.2]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.51it/s]
Epoch 1/5 - Train Loss: 0.5414, Train Acc: 82.18%, Val Loss: 1.0597, Val Acc: 74.18%, Best Val Acc: 74.18% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 725/725 [01:29<00:00,  8.14it/s, loss=0.333, acc=89.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.58it/s]
Epoch 2/5 - Train Loss: 0.3328, Train Acc: 89.36%, Val Loss: 1.1136, Val Acc: 74.13%, Best Val Acc: 74.18% (Epoch 1)
Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 725/725 [01:29<00:00,  8.08it/s, loss=0.28, acc=91.3]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.49it/s]
Epoch 3/5 - Train Loss: 0.2796, Train Acc: 91.31%, Val Loss: 0.9508, Val Acc: 76.85%, Best Val Acc: 76.85% (Epoch 3)
Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 725/725 [01:29<00:00,  8.06it/s, loss=0.252, acc=92.3]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.50it/s]
Epoch 4/5 - Train Loss: 0.2521, Train Acc: 92.27%, Val Loss: 1.1021, Val Acc: 76.12%, Best Val Acc: 76.85% (Epoch 3)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 725/725 [01:30<00:00,  8.04it/s, loss=0.235, acc=92.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:12<00:00,  7.48it/s]
Epoch 5/5 - Train Loss: 0.2347, Train Acc: 92.84%, Val Loss: 1.1990, Val Acc: 72.31%, Best Val Acc: 76.85% (Epoch 3)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.49it/s]
Skipping GradCAM visualization for frozen models

Fold 8 Evaluation:
Test Loss: 0.9269, Test Accuracy: 70.26%

================================================================================
Training on Fold 9
Train Folds: [1, 2, 3, 4, 5, 6, 7, 10]
Val Fold: [8]
Test Fold: [9]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 728/728 [01:30<00:00,  8.04it/s, loss=0.546, acc=81.9]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.37it/s]
Epoch 1/5 - Train Loss: 0.5465, Train Acc: 81.93%, Val Loss: 0.8718, Val Acc: 72.45%, Best Val Acc: 72.45% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 728/728 [01:32<00:00,  7.90it/s, loss=0.338, acc=89.1]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.58it/s]
Epoch 2/5 - Train Loss: 0.3385, Train Acc: 89.12%, Val Loss: 0.9012, Val Acc: 73.62%, Best Val Acc: 73.62% (Epoch 2)
Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 728/728 [01:30<00:00,  8.02it/s, loss=0.289, acc=91]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.58it/s]
Epoch 3/5 - Train Loss: 0.2887, Train Acc: 90.97%, Val Loss: 0.9015, Val Acc: 74.73%, Best Val Acc: 74.73% (Epoch 3)
Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 728/728 [01:31<00:00,  7.92it/s, loss=0.256, acc=92]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.73it/s]
Epoch 4/5 - Train Loss: 0.2558, Train Acc: 91.97%, Val Loss: 0.9446, Val Acc: 73.97%, Best Val Acc: 74.73% (Epoch 3)
Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 728/728 [01:32<00:00,  7.91it/s, loss=0.238, acc=92.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.45it/s]
Epoch 5/5 - Train Loss: 0.2377, Train Acc: 92.75%, Val Loss: 0.9748, Val Acc: 73.12%, Best Val Acc: 74.73% (Epoch 3)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.28it/s]
Skipping GradCAM visualization for frozen models

Fold 9 Evaluation:
Test Loss: 0.8178, Test Accuracy: 82.44%

================================================================================
Training on Fold 10
Train Folds: [1, 2, 3, 4, 5, 6, 7, 8]
Val Fold: [9]
Test Fold: [10]
================================================================================

/home/jupyter-st125462/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 727/727 [01:30<00:00,  8.07it/s, loss=0.553, acc=81.6]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.57it/s]
Epoch 1/5 - Train Loss: 0.5526, Train Acc: 81.62%, Val Loss: 0.8102, Val Acc: 80.49%, Best Val Acc: 80.49% (Epoch 1)
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 727/727 [01:30<00:00,  8.06it/s, loss=0.333, acc=89.4]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.34it/s]
Epoch 2/5 - Train Loss: 0.3326, Train Acc: 89.38%, Val Loss: 0.8937, Val Acc: 78.79%, Best Val Acc: 80.49% (Epoch 1)
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 727/727 [01:30<00:00,  7.99it/s, loss=0.289, acc=90.8]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.25it/s]
Epoch 3/5 - Train Loss: 0.2890, Train Acc: 90.84%, Val Loss: 0.8441, Val Acc: 80.83%, Best Val Acc: 80.83% (Epoch 3)
Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 727/727 [01:30<00:00,  8.00it/s, loss=0.262, acc=91.7]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:11<00:00,  7.59it/s]
Epoch 4/5 - Train Loss: 0.2617, Train Acc: 91.75%, Val Loss: 0.9205, Val Acc: 79.88%, Best Val Acc: 80.83% (Epoch 3)
Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 727/727 [01:29<00:00,  8.09it/s, loss=0.225, acc=93]
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:12<00:00,  7.40it/s]
Epoch 5/5 - Train Loss: 0.2254, Train Acc: 92.97%, Val Loss: 0.7997, Val Acc: 82.48%, Best Val Acc: 82.48% (Epoch 5)
Validating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:12<00:00,  7.27it/s]
Skipping GradCAM visualization for frozen models

Fold 10 Evaluation:
Test Loss: 0.9525, Test Accuracy: 78.34%

================================================================================
Summary of results for alexnet
================================================================================
Average Test Accuracy: 73.89%
Individual Fold Test Accuracies: [72.69901571403902, 74.22520661157024, 74.3298969072165, 71.88569472963724, 71.94955691888207, 68.69744293804702, 74.11245116358077, 70.25976320904753, 82.44073748902547, 78.33537331701346]
Summary saved to output/alexnet/summary.json
Total execution time: 5455.20 seconds (1.52 hours)